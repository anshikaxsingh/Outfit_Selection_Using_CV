# -*- coding: utf-8 -*-
"""fashion-MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zE4KynovOOHb2vm7u82xpkrjoXUNRfQJ

**Data is obtained from** `keras.datasets.fashion_mnist`

`Features :`

Each training and test example is assigned to one of the following labels:

`Label- Description`

ðŸ‘• *T-shirt/top*

ðŸ‘–	*Trouser*

ðŸ§¥	*Pullover*

ðŸ‘—	*Dress*

ðŸ§¥	*Coat*

ðŸ‘¡	*Sandal*

ðŸ‘”	*Shirt*

ðŸ‘Ÿ	*Sneaker*

ðŸ‘œ	*Bag*

## Building the model

`Loading the data`
"""

# Import the necessary libraries

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from keras.utils import np_utils
import random

# Import the data from keras.dataset

(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()

# Check out the shape of the dataset

print("Train Images Shape:",train_images.shape)
print("Train Labels Shape:",train_labels.shape)
print("Test Images Shape:",test_images.shape)
print("Test Labels Shape:",test_labels.shape)

# Check out loaded images!

plt.figure()

fig,ax = plt.subplots(2,2)

ax[0][0].imshow(train_images[1])
ax[0][1].imshow(train_images[1000])
ax[1][0].imshow(train_images[22000])
ax[1][1].imshow(train_images[44000])

"""`Data pre-processing`"""

# We normalise the loaded images
# i.e we convert the pixel values which lie between 0-255 into values between 0-1

train_images = train_images/255.0
test_images = test_images/255.0

"""`Creating a model`"""

# We are building a sequential model

model = tf.keras.models.Sequential()

# Add the input layer

model.add(tf.keras.layers.Flatten(input_shape=(28,28)))

# Add a hidden layer

model.add(tf.keras.layers.Dense(units=128, activation="relu"))

# Add an output layer

model.add(tf.keras.layers.Dense(units=10))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""`Fit the training data to the model`"""

# fit the data to the model

history = model.fit(train_images, train_labels, epochs=10)

"""## Test the model on the test data"""

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)

# A helper function that returns 'red'/'black' depending on if its two input
# parameter matches or not.

def get_label_color(val1, val2):
  if val1 == val2:
    return 'black'
  else:
    return 'red'

# Predict the labels of digit images in our test dataset.

predictions = model.predict(test_images)

# As the model output 10 float representing the probability of the input image
# being a digit from 0 to 9, we need to find the largest probability value
# to find out which digit the model predicts to be most likely in the image.

prediction_digits = np.argmax(predictions, axis=1)

# Then plot 100 random test images and their predicted labels.
# If a prediction result is different from the label provided label in "test"
# dataset, we will highlight it in red color.

plt.figure(figsize=(18, 18))
for i in range(100):
  ax = plt.subplot(10, 10, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  image_index = random.randint(0, len(prediction_digits))
  plt.imshow(test_images[image_index], cmap=plt.cm.gray)
  ax.xaxis.label.set_color(get_label_color(prediction_digits[image_index],\
                                           test_labels[image_index]))
  plt.xlabel('Predicted: %d' % prediction_digits[image_index])
plt.show()